#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Live Detector for TwitCasting
é…ä¿¡æ¤œçŸ¥ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆ3æ®µéšãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç‰ˆï¼‰
Version: 5.2.0

ä¿®æ­£å†…å®¹:
- Streamlink Cookieä¿®æ­£ï¼ˆ--http-headerä½¿ç”¨ï¼‰
- Streamlinkã«UA/Refererè¿½åŠ 
- ã‚¨ãƒ©ãƒ¼è©³ç´°ã®å–å¾—å¼·åŒ–
- æ—¢å­˜æ©Ÿèƒ½ã¯å…¨ã¦ç¶­æŒ
"""
import json
import re
import sys
import os
import time
import logging
import shutil
import asyncio
from typing import Dict, Optional, Any
from urllib.request import urlopen, Request
from urllib.error import HTTPError, URLError
from pathlib import Path

# ãƒ­ã‚¬ãƒ¼è¨­å®š
logger = logging.getLogger("live_detector")
logger.setLevel(logging.INFO)
if not logger.handlers:
    handler = logging.StreamHandler(sys.stdout)
    handler.setFormatter(logging.Formatter("%(asctime)s [%(levelname)s] %(message)s"))
    logger.addHandler(handler)

# å®šæ•°
UA = ("Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 "
      "(KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36")
COOKIES_DIR = Path(__file__).resolve().parents[1] / "logs"
READ_SIZE = 512_000  # 512KBèª­å–

# ãƒ‡ãƒãƒƒã‚°ç”¨HTMLãƒ€ãƒ³ãƒ—ãƒ‘ã‚¹
DEBUG_HTML_PATH = COOKIES_DIR / "debug_live_detector.html"


class LiveDetector:
    """é…ä¿¡çŠ¶æ…‹æ¤œçŸ¥ï¼ˆ3æ®µéšãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""
    
    def __init__(self):
        self.timeout = 10  # HTTP timeout
        self.browser_timeout = 20  # Browser timeout
        self.streamlink_timeout = 10  # Streamlink timeout
        self._cookie_repair_attempted = False
        self._chrome = None  # é…å»¶åˆæœŸåŒ–ç”¨
        self._debug_mode = os.environ.get("DEBUG_LIVE_DETECTOR", "").lower() == "true"
    
    def _normalize_url(self, url: str) -> str:
        """
        URLæ­£è¦åŒ–ï¼ˆTwitCastingä»•æ§˜æº–æ‹ ï¼‰
        g:/ig:ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã¯ãƒ‘ã‚¹ã«æ®‹ã™
        """
        if not url:
            return ""
        
        url = url.strip()
        
        # ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹å¯¾å¿œï¼ˆTwitCastingã®ä»•æ§˜ã«åˆã‚ã›ã‚‹ï¼‰
        prefixes = ("c:", "g:", "ig:", "f:", "tw:")
        for pre in prefixes:
            if url.lower().startswith(pre):
                # ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹å¾Œã®éƒ¨åˆ†ã‚’å–å¾—
                name = url[len(pre):].strip()
                if not name:
                    return ""
                
                # g:/ig: ã¯ãƒ‘ã‚¹ã«ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’æ®‹ã™ï¼ˆå…¬å¼ä»•æ§˜ï¼‰
                if pre in ("g:", "ig:"):
                    return f"https://twitcasting.tv/{pre}{name}"
                
                # c:/f:/tw: ã¯å¾“æ¥ã©ãŠã‚Šç´ ã®ãƒ¦ãƒ¼ã‚¶å
                return f"https://twitcasting.tv/{name}"
        
        # /broadcasterã‚’å‰Šé™¤
        url = re.sub(r"/broadcaster/?$", "", url)
        
        # httpsã‚¹ã‚­ãƒ¼ãƒ ç¢ºä¿
        if not url.startswith("http"):
            url = f"https://twitcasting.tv/{url}"
        
        return url.rstrip("/")
    
    def _latest_enter_cookie_path(self) -> Optional[str]:
        """æœ€æ–°ã®cookies_enter_*.txtå–å¾—"""
        try:
            # latest_cookie_path.txt ã‚’æœ€å„ªå…ˆ
            latest = COOKIES_DIR / "latest_cookie_path.txt"
            if latest.exists():
                p = Path(latest.read_text(encoding="utf-8").strip())
                if p.exists():
                    return str(p)
            
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šmtimeã‚½ãƒ¼ãƒˆ
            files = sorted(
                COOKIES_DIR.glob("cookies_enter_*.txt"),
                key=os.path.getmtime,
                reverse=True
            )
            return str(files[0]) if files else None
        except Exception:
            return None
    
    def _check_cookie_integrity(self, path: str) -> Dict[str, bool]:
        """Cookieãƒ•ã‚¡ã‚¤ãƒ«ã®å®Œå…¨æ€§ãƒã‚§ãƒƒã‚¯"""
        result = {
            "exists": False,
            "has_tc_id": False,
            "has_tc_ss": False,
            "has_session": False,
            "is_complete": False
        }
        
        if not path or not os.path.exists(path):
            return result
        
        result["exists"] = True
        
        try:
            with open(path, "r", encoding="utf-8") as f:
                content = f.read()
                result["has_tc_id"] = "tc_id" in content
                result["has_tc_ss"] = "tc_ss" in content
                result["has_session"] = "_twitcasting_session" in content
                result["is_complete"] = result["has_tc_id"] and (
                    result["has_tc_ss"] or result["has_session"]
                )
        except Exception as e:
            logger.error(f"Cookie integrity check failed: {e}")
        
        return result
    
    def _build_cookie_header_from_netscape(self, path: str) -> str:
        """Netscapeå½¢å¼ã‹ã‚‰Cookieãƒ˜ãƒƒãƒ€æ§‹ç¯‰"""
        if not path or not os.path.exists(path):
            return ""
        
        wanted = {}
        try:
            with open(path, "r", encoding="utf-8") as f:
                for line in f:
                    if line.startswith("#") or line.count("\t") < 6:
                        continue
                    parts = line.rstrip("\n").split("\t")
                    if len(parts) >= 7:
                        name, value = parts[-2], parts[-1]
                        # é‡è¦ãªCookieã‚’å…¨ã¦åé›†
                        if name in ("tc_id", "tc_ss", "_twitcasting_session", 
                                   "keep", "mfadid", "did", "tc_s", "tc_u"):
                            wanted[name] = value
        except Exception as e:
            logger.error(f"Cookie parse error: {e}")
            return ""
        
        items = []
        # èªè¨¼å¼·åº¦ã®é«˜ã„é †ã§å…¥ã‚Œã‚‹
        if "_twitcasting_session" in wanted:
            items.append(f'_twitcasting_session={wanted["_twitcasting_session"]}')
        if "tc_ss" in wanted:
            items.append(f'tc_ss={wanted["tc_ss"]}')
        if "tc_s" in wanted:
            items.append(f'tc_s={wanted["tc_s"]}')
        if "tc_id" in wanted:
            items.append(f'tc_id={wanted["tc_id"]}')
        if "tc_u" in wanted:
            items.append(f'tc_u={wanted["tc_u"]}')
        # ãã®ä»–ã®Cookie
        for name in ("keep", "mfadid", "did"):
            if name in wanted:
                items.append(f'{name}={wanted[name]}')
        
        return "; ".join(items)
    
    def _extract_movie_id(self, html: str) -> Optional[str]:
        """HTMLã‹ã‚‰movie_idæŠ½å‡ºï¼ˆè¤‡æ•°ãƒ‘ã‚¿ãƒ¼ãƒ³å¯¾å¿œï¼‰"""
        patterns = [
            r'data-movie-id="(\d+)"',
            r'"movie_id"\s*:\s*(\d+)',
            r"movieId:\s*'(\d+)'",
            r'movie_id=(\d+)',
            r'data-movie-id=["\'](\d+)["\']',
        ]
        
        for pattern in patterns:
            m = re.search(pattern, html, re.IGNORECASE)
            if m:
                return m.group(1)
        
        return None
    
    def _check_status_http(self, url: str) -> Dict:
        """HTTPãƒ™ãƒ¼ã‚¹ã®é…ä¿¡çŠ¶æ…‹ãƒã‚§ãƒƒã‚¯ï¼ˆæ—¢å­˜ãƒ»é«˜é€Ÿï¼‰"""
        # æ³¨ï¼šurlã¯æ—¢ã«æ­£è¦åŒ–æ¸ˆã¿ã®ã‚‚ã®ãŒæ¸¡ã•ã‚Œã‚‹å‰æ
        if not url:
            return {
                "is_live": False,
                "movie_id": None,
                "reason": "INVALID_URL",
                "detail": "ç„¡åŠ¹ãªURL",
                "method": "http"
            }
        
        integrity = None
        
        # Cookieå®Œå…¨æ€§ãƒã‚§ãƒƒã‚¯
        cookie_path = self._latest_enter_cookie_path()
        if cookie_path:
            integrity = self._check_cookie_integrity(cookie_path)
            if not integrity["has_session"]:
                logger.warning(f"âš ï¸ Cookie missing _twitcasting_session: {cookie_path}")
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥å›é¿
        bust = str(int(time.time()))
        probe_url = url + ("?t=" + bust if "?" not in url else "&t=" + bust)
        
        try:
            # HTTPãƒªã‚¯ã‚¨ã‚¹ãƒˆæ§‹ç¯‰
            req = Request(probe_url)
            req.add_header("User-Agent", UA)
            req.add_header("Accept", "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8")
            req.add_header("Accept-Language", "ja,en-US;q=0.8,en;q=0.6")
            req.add_header("Cache-Control", "no-cache")
            req.add_header("Pragma", "no-cache")
            req.add_header("Referer", url)
            
            # Cookieä»˜ä¸
            if cookie_path:
                cookie_header = self._build_cookie_header_from_netscape(cookie_path)
                if cookie_header:
                    req.add_header("Cookie", cookie_header)
                    logger.debug(f"Cookie header set: {len(cookie_header)} chars")
            else:
                logger.warning("No cookie file found for authentication")
            
            with urlopen(req, timeout=self.timeout) as response:
                html = response.read(READ_SIZE).decode("utf-8", errors="ignore")
                
                # ãƒ‡ãƒãƒƒã‚°ç”¨HTMLãƒ€ãƒ³ãƒ—
                if self._debug_mode:
                    try:
                        DEBUG_HTML_PATH.write_text(html[:65536], encoding="utf-8")
                        logger.info(f"Debug HTML saved to {DEBUG_HTML_PATH}")
                    except Exception:
                        pass
                
                # AUTH_REQUIREDåˆ¤å®šï¼ˆæœ€å„ªå…ˆï¼‰
                auth_patterns = [
                    'tw-gate-required',
                    'membership-required',
                    'group-required',
                    'é™å®šé…ä¿¡',
                    'ãƒ­ã‚°ã‚¤ãƒ³ãŒå¿…è¦',
                    'ãƒ¡ãƒ³ãƒãƒ¼é™å®š',
                    'ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼é™å®š',
                    'ã‚°ãƒ«ãƒ¼ãƒ—é™å®š',
                    'membershipjoinplans',
                    'group_member_only',
                    'follower_only'
                ]
                
                auth_regex = '|'.join(re.escape(p) for p in auth_patterns)
                if re.search(auth_regex, html, re.IGNORECASE):
                    detail = "è¦ãƒ­ã‚°ã‚¤ãƒ³ï¼ˆãƒ¡ãƒ³é™/ã‚°ãƒ«é™ã®å¯èƒ½æ€§ï¼‰"
                    if cookie_path and integrity and not integrity["has_session"]:
                        detail += " - Cookieä¸å®Œå…¨(_twitcasting_sessionæ¬ è½)"
                    
                    return {
                        "is_live": False,
                        "movie_id": None,
                        "reason": "AUTH_REQUIRED",
                        "detail": detail,
                        "cookie_incomplete": cookie_path and integrity and not integrity["has_session"],
                        "method": "http"
                    }
                
                # æ‹¡å¼µLIVEåˆ¤å®šãƒ‘ã‚¿ãƒ¼ãƒ³
                live_patterns = [
                    # æ—¢å­˜ãƒ‘ã‚¿ãƒ¼ãƒ³
                    r'["\']is_live["\']\s*:\s*true',
                    r'"is_live"\s*:\s*true',
                    r"'is_live'\s*:\s*true",
                    r'data-is-live\s*=\s*["\']?true["\']?',
                    r'data-is-live="true"',
                    r"data-is-live='true'",
                    # æ‹¡å¼µãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆè¡¨è¨˜ã‚†ã‚Œå¯¾å¿œï¼‰
                    r'["\']isOnlive["\']\s*:\s*true',
                    r'["\']is_onlive["\']\s*:\s*(true|1)',
                    r'data-is-onlive\s*=\s*["\']?(true|1)["\']?',
                    r'isLive\s*:\s*true',
                    r'onLive\s*:\s*true',
                    # é–“æ¥çš„ãªå…†å€™
                    r'tw-player-container',
                    r'<video[^>]*>',
                    r'class="tw-movie-thumbnail2"',
                ]
                
                is_live = False
                for pattern in live_patterns:
                    if re.search(pattern, html, re.IGNORECASE):
                        is_live = True
                        logger.debug(f"Live pattern matched: {pattern}")
                        break
                
                # JSON-LDãƒã‚§ãƒƒã‚¯ï¼ˆè¿½åŠ ã®å®‰å…¨ç¶²ï¼‰
                if not is_live:
                    for m in re.finditer(
                        r'<script[^>]+application/ld\+json[^>]*>(.*?)</script>',
                        html, re.IGNORECASE | re.DOTALL
                    ):
                        try:
                            j = json.loads(m.group(1))
                            if isinstance(j, dict) and str(j.get("isLiveBroadcast", "")).lower() == "true":
                                is_live = True
                                logger.debug("Live detected via JSON-LD")
                                break
                        except Exception:
                            pass
                
                # movie_idæŠ½å‡º
                movie_id = self._extract_movie_id(html)
                
                if is_live:
                    logger.info(f"âœ… LIVE detected (HTTP): {url} (movie_id={movie_id})")
                    return {
                        "is_live": True,
                        "movie_id": movie_id,
                        "reason": "LIVE",
                        "detail": "é…ä¿¡ä¸­",
                        "method": "http"
                    }
                
                # ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ã ãŒmovie_idãŒã‚ã‚‹å ´åˆã¯è¦æ³¨æ„
                if movie_id:
                    logger.warning(f"âš ï¸ movie_id={movie_id} found but NOT_LIVE (HTTP)")
                
                return {
                    "is_live": False,
                    "movie_id": movie_id,
                    "reason": "NOT_LIVE",
                    "detail": "é…ä¿¡ã—ã¦ã„ãªã„",
                    "method": "http",
                    "needs_browser_check": bool(movie_id)  # movie_idãŒã‚ã‚Œã°è¦å†æ¤œè¨¼
                }
        
        except HTTPError as e:
            if e.code in (401, 403):
                detail = f"HTTP {e.code} - èªè¨¼å¿…è¦"
                if cookie_path and integrity and not integrity["has_session"]:
                    detail += " (_twitcasting_sessionæ¬ è½ã®å¯èƒ½æ€§å¤§)"
                
                return {
                    "is_live": False,
                    "movie_id": None,
                    "reason": "AUTH_REQUIRED",
                    "detail": detail,
                    "http_code": e.code,
                    "cookie_incomplete": cookie_path and integrity and not integrity["has_session"],
                    "method": "http"
                }
            else:
                return {
                    "is_live": False,
                    "movie_id": None,
                    "reason": f"HTTP_{e.code}",
                    "detail": f"HTTPã‚¨ãƒ©ãƒ¼ï¼ˆ{e.code}ï¼‰",
                    "method": "http"
                }
        
        except URLError as e:
            return {
                "is_live": False,
                "movie_id": None,
                "reason": "NETWORK_ERROR",
                "detail": f"é€šä¿¡ã‚¨ãƒ©ãƒ¼: {str(e)}",
                "method": "http"
            }
        
        except Exception as e:
            return {
                "is_live": False,
                "movie_id": None,
                "reason": "UNKNOWN_ERROR",
                "detail": f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {str(e)}",
                "method": "http"
            }
    
    async def _get_chrome(self):
        """é…å»¶åˆæœŸåŒ–ã§Chromeå–å¾—"""
        if not self._chrome:
            try:
                sys.path.insert(0, str(Path(__file__).resolve().parents[1]))
                try:
                    from core.chrome_singleton import get_chrome_singleton
                except ImportError:
                    from chrome_singleton import get_chrome_singleton
                self._chrome = get_chrome_singleton()
                logger.info("Chrome singleton initialized for browser detection")
            except Exception as e:
                logger.error(f"Failed to get Chrome singleton: {e}")
                return None
        return self._chrome
    
    async def _check_status_browser(self, url: str) -> Dict:
        """
        ãƒ–ãƒ©ã‚¦ã‚¶ãƒ™ãƒ¼ã‚¹ã®é…ä¿¡çŠ¶æ…‹ãƒã‚§ãƒƒã‚¯ï¼ˆJavaScriptå®Ÿè¡Œå¯¾å¿œï¼‰
        æ°¸ç¶šã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä½¿ç”¨ã§é™å®šé…ä¿¡å¯¾å¿œ
        """
        chrome = await self._get_chrome()
        if not chrome:
            return {
                "is_live": False,
                "movie_id": None,
                "reason": "BROWSER_UNAVAILABLE",
                "detail": "ãƒ–ãƒ©ã‚¦ã‚¶åˆæœŸåŒ–å¤±æ•—",
                "method": "browser"
            }
        
        ctx = None
        page = None
        
        try:
            # æ°¸ç¶š+ãƒ­ã‚°ã‚¤ãƒ³æ¸ˆã¿ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§æ¤œçŸ¥ï¼ˆéŒ²ç”»ã¨åŒã˜æ¡ä»¶ï¼‰
            ctx = await chrome.ensure_headless(persistent=True)
            page = await ctx.new_page()
            
            logger.info(f"Browser check starting: {url}")
            
            # ãƒšãƒ¼ã‚¸èª­ã¿è¾¼ã¿
            await page.goto(url, wait_until="networkidle", timeout=15000)
            await page.wait_for_timeout(2000)  # JSå®Ÿè¡Œå¾…ã¡
            
            # JavaScriptã§ç›´æ¥is_liveã‚’å–å¾—
            is_live = await page.evaluate("""
                () => {
                    // è¤‡æ•°ã®å ´æ‰€ã‹ã‚‰æ¢ã™
                    if (typeof window.is_live !== 'undefined') return window.is_live;
                    if (window.App && window.App.is_live) return window.App.is_live;
                    if (window.TwitCasting && window.TwitCasting.is_live) return window.TwitCasting.is_live;
                    
                    // dataå±æ€§ã‹ã‚‰
                    const el = document.querySelector('[data-is-live]');
                    if (el) return el.dataset.isLive === 'true' || el.dataset.isLive === '1';
                    
                    // JSONã‹ã‚‰
                    const scripts = document.querySelectorAll('script');
                    for (const script of scripts) {
                        const text = script.textContent || '';
                        // is_liveç³»
                        let match = text.match(/"is_live"\s*:\s*(true|false|1|0)/i);
                        if (match) return match[1] === 'true' || match[1] === '1';
                        // isOnliveç³»
                        match = text.match(/"isOnlive"\s*:\s*(true|false|1|0)/i);
                        if (match) return match[1] === 'true' || match[1] === '1';
                    }
                    
                    // videoã‚¿ã‚°ã®å­˜åœ¨
                    const video = document.querySelector('video');
                    if (video && video.src) return true;
                    
                    return false;
                }
            """)
            
            # movie_idå–å¾—
            movie_id = await page.evaluate("""
                () => {
                    // dataå±æ€§
                    let el = document.querySelector('[data-movie-id]');
                    if (el) return el.dataset.movieId;
                    
                    // JSONã‹ã‚‰
                    const scripts = document.querySelectorAll('script');
                    for (const script of scripts) {
                        const match = (script.textContent || '').match(/"movie_id"\s*:\s*(\d+)/);
                        if (match) return match[1];
                    }
                    
                    return null;
                }
            """)
            
            # AUTH_REQUIREDåˆ¤å®š
            if not is_live:
                auth_required = await page.evaluate("""
                    () => {
                        const text = document.body.textContent.toLowerCase();
                        const hasAuthText = text.includes('ãƒ­ã‚°ã‚¤ãƒ³ãŒå¿…è¦') || 
                                           text.includes('ãƒ¡ãƒ³ãƒãƒ¼é™å®š') ||
                                           text.includes('ã‚°ãƒ«ãƒ¼ãƒ—é™å®š') ||
                                           text.includes('ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼é™å®š');
                        const hasAuthElement = document.querySelector('.tw-gate-required') !== null ||
                                              document.querySelector('[class*="membership"]') !== null;
                        return hasAuthText || hasAuthElement;
                    }
                """)
                
                if auth_required:
                    return {
                        "is_live": False,
                        "movie_id": movie_id,
                        "reason": "AUTH_REQUIRED",
                        "detail": "è¦ãƒ­ã‚°ã‚¤ãƒ³ï¼ˆãƒ–ãƒ©ã‚¦ã‚¶æ¤œè¨¼ï¼‰",
                        "method": "browser"
                    }
            
            if is_live:
                logger.info(f"âœ… LIVE detected (Browser): {url} (movie_id={movie_id})")
                return {
                    "is_live": True,
                    "movie_id": movie_id,
                    "reason": "LIVE",
                    "detail": "é…ä¿¡ä¸­ï¼ˆãƒ–ãƒ©ã‚¦ã‚¶æ¤œè¨¼ï¼‰",
                    "method": "browser"
                }
            else:
                return {
                    "is_live": False,
                    "movie_id": movie_id,
                    "reason": "NOT_LIVE",
                    "detail": "é…ä¿¡ã—ã¦ã„ãªã„ï¼ˆãƒ–ãƒ©ã‚¦ã‚¶æ¤œè¨¼ï¼‰",
                    "method": "browser"
                }
                
        except Exception as e:
            logger.error(f"Browser check error: {e}")
            return {
                "is_live": False,
                "movie_id": None,
                "reason": "BROWSER_ERROR",
                "detail": f"ãƒ–ãƒ©ã‚¦ã‚¶ã‚¨ãƒ©ãƒ¼: {str(e)}",
                "method": "browser"
            }
        finally:
            if page:
                try:
                    await page.close()
                except Exception:
                    pass
    
    async def _check_status_streamlink(self, url: str) -> Dict:
        """
        Streamlinkãƒ—ãƒ­ãƒ¼ãƒ–ï¼ˆæœ€çµ‚æ‰‹æ®µï¼‰
        ä¿®æ­£ï¼šCookie/UA/Refererã‚’æ­£ã—ããƒ˜ãƒƒãƒ€ãƒ¼æŒ‡å®š
        """
        if not shutil.which("streamlink"):
            return {
                "is_live": False,
                "movie_id": None,
                "reason": "STREAMLINK_UNAVAILABLE",
                "detail": "Streamlinkæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«",
                "method": "streamlink"
            }
        
        try:
            logger.info(f"Streamlink probe starting: {url}")
            
            # Cookieãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å–å¾—
            cookie_path = self._latest_enter_cookie_path()
            
            # Streamlinkã‚³ãƒãƒ³ãƒ‰æ§‹ç¯‰
            cmd = ["streamlink", "--json", url, "best"]
            
            # ä¿®æ­£ï¼šCookieã‚’ãƒ˜ãƒƒãƒ€ãƒ¼ã¨ã—ã¦æ­£ã—ãæ¸¡ã™
            if cookie_path and os.path.exists(cookie_path):
                cookie_header = self._build_cookie_header_from_netscape(cookie_path)
                if cookie_header:
                    cmd.extend(["--http-header", f"Cookie={cookie_header}"])
                    logger.debug(f"Streamlink cookie header injected ({len(cookie_header)} chars)")
                else:
                    logger.warning("Cookie file exists but no valid cookies extracted")
            
            # UAè¿½åŠ ï¼ˆTwitCastingã¯å¿…é ˆï¼‰
            cmd.extend(["--http-header", f"User-Agent={UA}"])
            
            # Refererè¿½åŠ ï¼ˆé‡è¦ï¼‰
            cmd.extend(["--http-header", f"Referer={url}"])
            
            # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®š
            cmd.extend(["--http-timeout", str(self.streamlink_timeout)])
            
            # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ãªã‚‰verbose
            if self._debug_mode:
                cmd.append("--verbose-player")
            
            logger.debug(f"Streamlink command: {' '.join(cmd[:3])}...")
            
            proc = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            stdout, stderr = await asyncio.wait_for(
                proc.communicate(), 
                timeout=self.streamlink_timeout + 2
            )
            
            stdout_str = stdout.decode("utf-8", errors="ignore")
            stderr_str = stderr.decode("utf-8", errors="ignore")
            
            # ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›
            if self._debug_mode and stderr_str:
                logger.debug(f"Streamlink stderr: {stderr_str[:500]}")
            
            if proc.returncode == 0:
                # JSONå‡ºåŠ›ã‚’ãƒ‘ãƒ¼ã‚¹
                try:
                    result_json = json.loads(stdout_str)
                    if "streams" in result_json and result_json["streams"]:
                        logger.info(f"âœ… LIVE detected (Streamlink): {url}")
                        logger.debug(f"Available streams: {list(result_json['streams'].keys())}")
                        return {
                            "is_live": True,
                            "movie_id": None,
                            "reason": "LIVE",
                            "detail": "é…ä¿¡ä¸­ï¼ˆStreamlinkãƒ—ãƒ­ãƒ¼ãƒ–ï¼‰",
                            "method": "streamlink",
                            "streams": list(result_json["streams"].keys())
                        }
                except json.JSONDecodeError:
                    # JSONãƒ‘ãƒ¼ã‚¹å¤±æ•—ã§ã‚‚ã€streamsã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒã‚ã‚Œã°LIVEåˆ¤å®š
                    if '"streams"' in stdout_str:
                        logger.info(f"âœ… LIVE detected (Streamlink, non-JSON): {url}")
                        return {
                            "is_live": True,
                            "movie_id": None,
                            "reason": "LIVE",
                            "detail": "é…ä¿¡ä¸­ï¼ˆStreamlinkãƒ—ãƒ­ãƒ¼ãƒ–ï¼‰",
                            "method": "streamlink"
                        }
            
            # ã‚¨ãƒ©ãƒ¼è©³ç´°ã‚’è§£æ
            error_detail = "é…ä¿¡ã—ã¦ã„ãªã„"
            if "403" in stderr_str or "403" in stdout_str:
                error_detail = "èªè¨¼ã‚¨ãƒ©ãƒ¼ï¼ˆ403ï¼‰"
            elif "404" in stderr_str or "404" in stdout_str:
                error_detail = "é…ä¿¡ãŒè¦‹ã¤ã‹ã‚‰ãªã„ï¼ˆ404ï¼‰"
            elif "No playable streams" in stdout_str:
                error_detail = "å†ç”Ÿå¯èƒ½ãªã‚¹ãƒˆãƒªãƒ¼ãƒ ãªã—"
            elif proc.returncode != 0:
                error_detail = f"Streamlinkçµ‚äº†ã‚³ãƒ¼ãƒ‰: {proc.returncode}"
            
            return {
                "is_live": False,
                "movie_id": None,
                "reason": "NOT_LIVE",
                "detail": error_detail,
                "method": "streamlink"
            }
            
        except asyncio.TimeoutError:
            return {
                "is_live": False,
                "movie_id": None,
                "reason": "STREAMLINK_TIMEOUT",
                "detail": f"Streamlinkã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆ{self.streamlink_timeout}ç§’ï¼‰",
                "method": "streamlink"
            }
        except Exception as e:
            logger.error(f"Streamlink probe error: {e}")
            return {
                "is_live": False,
                "movie_id": None,
                "reason": "STREAMLINK_ERROR",
                "detail": f"Streamlinkã‚¨ãƒ©ãƒ¼: {str(e)}",
                "method": "streamlink"
            }
    
    async def check_live(self, url: str) -> Dict:
        """
        3æ®µéšãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯é…ä¿¡ãƒã‚§ãƒƒã‚¯
        1. HTTPæ¤œçŸ¥ï¼ˆé«˜é€Ÿï¼‰
        2. ãƒ–ãƒ©ã‚¦ã‚¶æ¤œçŸ¥ï¼ˆmovie_idãŒã‚ã‚‹å ´åˆï¼‰
        3. Streamlinkãƒ—ãƒ­ãƒ¼ãƒ–ï¼ˆæœ€çµ‚æ‰‹æ®µï¼‰
        
        é‡è¦ï¼šæœ€åˆã«æ­£è¦åŒ–ã—ã¦ã€å…¨æ®µéšã§åŒã˜URLã‚’ä½¿ç”¨
        """
        # æœ€åˆã«ä¸€åº¦ã ã‘æ­£è¦åŒ–ã—ã€å…¨æ®µã§åŒã˜URLã‚’ä½¿ã†
        normalized_url = self._normalize_url(url)
        
        if not normalized_url:
            return {
                "is_live": False,
                "movie_id": None,
                "reason": "INVALID_URL",
                "detail": "ç„¡åŠ¹ãªURL",
                "original_url": url
            }
        
        logger.info(f"Checking URL: {url} -> {normalized_url}")
        
        # Stage 1: HTTPæ¤œçŸ¥ï¼ˆé«˜é€Ÿãƒ»è»½é‡ï¼‰
        result = await asyncio.get_running_loop().run_in_executor(
            None, self._check_status_http, normalized_url
        )
        
        # HTTPã§ç¢ºå®šã—ãŸå ´åˆã¯å³è¿”å´
        if result.get("is_live") or result.get("reason") == "AUTH_REQUIRED":
            return result
        
        # Stage 2: movie_idãŒã‚ã‚Œã°ãƒ–ãƒ©ã‚¦ã‚¶æ¤œçŸ¥
        if result.get("needs_browser_check") or result.get("movie_id"):
            logger.info(f"âš ï¸ movie_id found, escalating to browser check")
            browser_result = await self._check_status_browser(normalized_url)
            
            # ãƒ–ãƒ©ã‚¦ã‚¶ã§ç¢ºå®šã—ãŸå ´åˆ
            if browser_result.get("is_live") or browser_result.get("reason") == "AUTH_REQUIRED":
                return browser_result
            
            # ã¾ã movie_idãŒã‚ã‚‹å ´åˆã¯è¦æ³¨æ„
            if browser_result.get("movie_id"):
                logger.warning(f"âš ï¸ movie_id={browser_result['movie_id']} still NOT_LIVE after browser check")
                
                # Stage 3: Streamlinkãƒ—ãƒ­ãƒ¼ãƒ–ï¼ˆæœ€çµ‚æ‰‹æ®µï¼‰
                logger.info("Escalating to Streamlink probe")
                streamlink_result = await self._check_status_streamlink(normalized_url)
                
                if streamlink_result.get("is_live"):
                    # movie_idã‚’å¼•ãç¶™ã
                    streamlink_result["movie_id"] = browser_result.get("movie_id")
                    return streamlink_result
        
        # å…¨æ®µéšã§NOT_LIVE
        return result
    
    # äº’æ›æ€§ã®ãŸã‚ã®åˆ¥å
    async def check_status(self, url: str) -> Dict:
        """äº’æ›ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹"""
        return await self.check_live(url)
    
    async def check_live_status(self, url: str) -> Dict:
        """äº’æ›ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹"""
        return await self.check_live(url)
    
    async def check_with_cookie_repair(self, url: str) -> Dict:
        """Cookieè‡ªå‹•ä¿®å¾©æ©Ÿèƒ½ä»˜ããƒã‚§ãƒƒã‚¯ï¼ˆäº’æ›æ€§ç¶­æŒï¼‰"""
        result = await self.check_live(url)
        
        # AUTH_REQUIRED ã‹ã¤ Cookieä¸å®Œå…¨ ã‹ã¤ æœªä¿®å¾©ãªã‚‰
        if (result.get("reason") == "AUTH_REQUIRED" and 
            result.get("cookie_incomplete") and 
            not self._cookie_repair_attempted):
            
            logger.warning("ğŸ”§ Cookie repair needed - attempting re-login...")
            self._cookie_repair_attempted = True
            
            try:
                sys.path.insert(0, str(Path(__file__).resolve().parents[1]))
                try:
                    from recorder_wrapper import RecorderWrapper
                except ImportError:
                    from auto.recorder_wrapper import RecorderWrapper
                
                logger.info("Forcing re-login to obtain _twitcasting_session...")
                success = await RecorderWrapper.ensure_login(force=True)
                
                if success:
                    logger.info("âœ… Re-login successful, waiting for cookie propagation...")
                    await asyncio.sleep(1.5)
                    
                    # å†ãƒã‚§ãƒƒã‚¯
                    logger.info("Re-checking after cookie repair...")
                    result = await self.check_live(url)
                    logger.info(f"Re-check result: reason={result.get('reason')}, "
                               f"is_live={result.get('is_live')}")
                else:
                    logger.error("âŒ Re-login failed")
                    
            except Exception as e:
                logger.error(f"Cookie repair failed: {e}")
        
        return result


# ãƒ†ã‚¹ãƒˆç”¨
if __name__ == "__main__":
    import asyncio
    
    async def test():
        if len(sys.argv) < 2:
            print("Usage: python live_detector.py <URL>")
            print("\nOptions:")
            print("  DEBUG_LIVE_DETECTOR=true  - Enable debug output")
            print("\nExamples:")
            print("  python live_detector.py https://twitcasting.tv/username")
            print("  python live_detector.py c:username")
            print("  python live_detector.py g:117191...")
            sys.exit(1)
        
        detector = LiveDetector()
        url = sys.argv[1]
        
        print(f"Original URL: {url}")
        print(f"Normalized URL: {detector._normalize_url(url)}")
        print(f"Read size: {READ_SIZE} bytes")
        print(f"Debug mode: {detector._debug_mode}")
        
        # CookieçŠ¶æ…‹ç¢ºèª
        cookie_path = detector._latest_enter_cookie_path()
        if cookie_path:
            integrity = detector._check_cookie_integrity(cookie_path)
            print(f"\nCookie file: {os.path.basename(cookie_path)}")
            print(f"  tc_id: {'âœ…' if integrity['has_tc_id'] else 'âŒ'}")
            print(f"  tc_ss: {'âœ…' if integrity['has_tc_ss'] else 'âŒ'}")
            print(f"  _twitcasting_session: {'âœ…' if integrity['has_session'] else 'âŒ'}")
            print(f"  Complete: {'âœ…' if integrity['is_complete'] else 'âŒ'}")
            
            # Cookieãƒ˜ãƒƒãƒ€ãƒ¼æ§‹ç¯‰ãƒ†ã‚¹ãƒˆ
            cookie_header = detector._build_cookie_header_from_netscape(cookie_path)
            if cookie_header:
                print(f"  Cookie header: {len(cookie_header)} chars")
                if detector._debug_mode:
                    print(f"  First 100 chars: {cookie_header[:100]}...")
        else:
            print("\nâš ï¸ No cookie file found")
        
        print("\n=== Starting 3-stage detection ===")
        result = await detector.check_live(url)
        
        print("\n=== Result ===")
        print(json.dumps(result, indent=2, ensure_ascii=False))
        
        # åˆ¤å®šç†ç”±ã®èª¬æ˜
        if result.get("reason") == "AUTH_REQUIRED":
            print("\nâš ï¸  èªè¨¼ãŒå¿…è¦ãªé…ä¿¡ã§ã™")
            if result.get("cookie_incomplete"):
                print("    _twitcasting_sessionãŒä¸è¶³ã—ã¦ã„ã¾ã™")
            print("    ãƒ¡ãƒ³ãƒãƒ¼é™å®šã¾ãŸã¯ã‚°ãƒ«ãƒ¼ãƒ—é™å®šã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
        elif result.get("is_live"):
            print(f"\nâœ… é…ä¿¡ä¸­ã§ã™ï¼ˆæ¤œå‡ºæ–¹æ³•: {result.get('method', 'unknown')}ï¼‰")
            if result.get("movie_id"):
                print(f"    Movie ID: {result['movie_id']}")
            if result.get("streams"):
                print(f"    Available streams: {', '.join(result['streams'])}")
        else:
            print(f"\nâŒ é…ä¿¡ã—ã¦ã„ã¾ã›ã‚“ï¼ˆæ¤œè¨¼æ–¹æ³•: {result.get('method', 'unknown')}ï¼‰")
            if result.get("movie_id"):
                print(f"    Movie ID: {result['movie_id']} (è¦æ³¨æ„)")
        
        if detector._debug_mode and DEBUG_HTML_PATH.exists():
            print(f"\nğŸ“„ Debug HTML saved to: {DEBUG_HTML_PATH}")
    
    asyncio.run(test())